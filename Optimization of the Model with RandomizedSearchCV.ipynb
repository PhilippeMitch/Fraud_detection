{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of libraries.\n",
    "# Pandas offers in particular data structures and operations for manipulating digital tables and time series\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dataset\n",
    "data = pd.read_csv('prediction_de_fraud_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of predictive data and data to predict. \n",
    "# characteristics => predictive data\n",
    "# to_predict => data to predict\n",
    "\n",
    "# axis=1 means that we want to drop the column with the name 'isFraud'\n",
    "# The values are simply a familiar NumPy array\n",
    "characteristics = data.drop('isFraud', axis=1).values\n",
    "to_predict = data['isFraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will change change the categorical variable to numeric variable.\n",
    "# To do that we use the LabelEncoder \n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the labelencoder to the different fields\n",
    "labEnc_x = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics[:,1] = labEnc_x.fit_transform(characteristics[:,1])\n",
    "characteristics[:,3] = labEnc_x.fit_transform(characteristics[:,3])\n",
    "characteristics[:,6] = labEnc_x.fit_transform(characteristics[:,6]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train data in test data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(characteristics, to_predict, test_size=0.3, random_state=42, stratify=to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the random drill with default parameters\n",
    "random_forest_classifier = RandomForestClassifier(random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=50, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the data to our model\n",
    "random_forest_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9550561797752809\n"
     ]
    }
   ],
   "source": [
    "# let's assess the accuracy of our model from the test data.\n",
    "result_score = random_forest_classifier.score(X_test, Y_test)\n",
    "print(result_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for optimal parameters with RandomizeSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a dictionary of hyper parameter values.\n",
    "grid_params = {\n",
    "    # n_estimators is the number of trees to be used in the forest\n",
    "    'n_estimators':[100,200,300,400,500],\n",
    "    # max number of levels in each decision tree\n",
    "    'max_depth':[1,2,4,6,8],\n",
    "    # specifies the minimum number of samples that should be present in the leaf node after splitting a node\n",
    "    'min_samples_leaf':[0.05, 0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parallelTest\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.9s finished\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    extractor = parallelTest.ParallelExtractor()\n",
    "    extractor.runInParallel(numProcesses=2, numThreads=4)\n",
    "    rf_random = RandomizedSearchCV(estimator = random_forest_classifier, param_distributions = grid_params, n_iter = 1, cv=3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    rf_random.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500, 'min_samples_leaf': 0.05, 'max_depth': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the the best optimum hypermarameters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
